{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5000b6bc",
   "metadata": {},
   "source": [
    "# 텍스트 마이닝의 이론과 실제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec1dfe",
   "metadata": {},
   "source": [
    "## - 텍스트마이닝이란? \n",
    ": 텍스트로부터 하이퀄리티의 정보를 뽑아내는 과정 <br>\n",
    ": 텍스트(비정형 데이터)를 분석이 가능한 정형데이터로 변환하는 과정 -> NLP 등 분석방법을 사용 <br>\n",
    ": 정형 데이터로 패턴이나 트렌드를 찾아서 유용한 정보로 만들어 내는것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f9043",
   "metadata": {},
   "source": [
    "## - 텍스트 마이닝 단계\n",
    ": **문서** -> **Tokenize**(단어 단위로 쪼개는 작업)<br>\n",
    "-> **normalize**(표준화, 단어 원형으로 바꾸는 작업, 동음이의어 처리, 단수/복수 처리 등) <br>\n",
    "-> **POS-tagging**(품사태깅 or 형태소 분석 / 최소 의미단위로 나누어진 대상에 대해 품사를 부착) <br>\n",
    "-> **Chunking**(전 단계의 결과를 명사구, 형용사구, 분사구 등과 같은 말모듬으로 다시 합치는 과정) <br>\n",
    "-> **BOW** (문서를 벡터로 표현, 순서는 무시하고 문장에 어떤 단어가 있는가 확인하는, 단어가 몇번 들어가있는지 count하는 과정)  <br>\n",
    "-> **TFIDF** (단어의 count를 단어가 나타난 문서의 수로 나눠서 자주 등장하지 않는 단어의 weight를 올림  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb10da9",
   "metadata": {},
   "source": [
    "## - 텍스트 마이닝 방법론 \n",
    "- 나이브 베이즈 분류 : text categorization, 단어집합으로 이루어진 문서가 분류 C에 속할 확률 <br>\n",
    "ex) 스팸메일과 일반메일을 분류 <br>\n",
    "- 로지스틱 회귀분석 : 종속변수와 독립변수간의 관계를 구체적인 함수로 나타내어 향후 예측 모델에 활용 <br>\n",
    "- 감성분석 : 텍스트에 들어있는 의견이나 감성, 평가, 태도 등의 주관적인 정보를 컴퓨터를 통해 분석하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e146541",
   "metadata": {},
   "source": [
    "## - 텍스트 마이닝의 문제\n",
    "- 차원의 저주 : 각 데이터 간의 거리가 너무 멀게 위치, 문서에서 단어수를 카운트하면 한번만(적은 횟수) 나오는 단어가 많아서 발생하게 됨 \n",
    "- 해결방법 : 데이터를 많이 활용, 차원 축소의 방법\n",
    "- 단어 빈도의 불균형 : (Zif's law) 빈도수를 그래프로 나타내면 많이쓰이는 단어는 많이쓰이고 잘 안쓰이는 단어는 계속 안쓰임 -> 다수에 의해 결정되는 경향 -> 빈도가 높은 단어를 삭제\n",
    "- 단어가 쓰인 순서정보의 손실 <br>\n",
    "     -> 통계에 의한 의미 파악(문맥정보가 사라짐) vs 순서에 의한 의미 파악\n",
    "     [해결방안]\n",
    "     * Word2Vec : 문장에 나타난 단어들의 순서를 이용해 word embedding을 수행\n",
    "          - CBOW : 주변 단어들을 이용해 다음 단어를 예측\n",
    "          - Skip-Ngram : 한 단어의 주변단어들을 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6887a4",
   "metadata": {},
   "source": [
    "## - 문제의 해결방안 \n",
    "\n",
    "- ELMO : 사전 훈련된 언어 모델을 사용하는 워드 임베딩 방법론\n",
    "    Word2vec이나 GloVe는 고정된 벡터로 임베딩<br>\n",
    "    ex) 한국어로 '배' 라고 하면 그냥 ship으로 인식할수도 있는데, ELMO는 배(pear)과 배(ship)을 문맥을 파악하고 단어를 구분해줌\n",
    "    \n",
    "- Document Embedding : Word2Vec 모형에서 주변단어들에 더하여 document의 고유한 vector를 함께 학습함으로써 document에 대한 dense vector을 생성\n",
    "- RBM : 사전학습 목적으로 개발되었고, 사전학습을 통한 차원 축소에 사용 가능\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2743e78",
   "metadata": {},
   "source": [
    "# # 웹 크롤링1 - Static Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fb4bb",
   "metadata": {},
   "source": [
    "##  1. urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25655bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request \n",
    "\n",
    "#파이썬은 웹 사이트에 있는 데이터를 추출하기 위해 urllib 라이브러리 사용\n",
    "#urllib은 URL을 다루는 모듈을 모아 놓은 패키지\n",
    "#urllib.request 모듈은 웹 사이트에 있는 데이터에 접근하는 기능 제공, 또한 인증, 리다렉트, 쿠키처럼 인터넷을 이용한 다양한 요청과 처리가 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad0e6a",
   "metadata": {},
   "source": [
    "###     1.1. urllib.request를 이용한 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d713826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 읽어들이기 \n",
    "from urllib import request\n",
    "\n",
    "url=\"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename=\"test.png\"\n",
    "\n",
    "request.urlretrieve(url, savename)\n",
    "print(\"저장되었습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48ec7e",
   "metadata": {},
   "source": [
    "### 1.2. urlopen으로 파일에 저장하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4323685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다..\n"
     ]
    }
   ],
   "source": [
    "# URL과 저장경로 지정하기\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test1.png\"\n",
    "#다운로드\n",
    "mem = request.urlopen(url).read()\n",
    "#파일로 저장하기, wb는 쓰기와 바이너리모드\n",
    "with open(savename, mode=\"wb\") as f:\n",
    "    f.write(mem)\n",
    "    print(\"저장되었습니다..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4801661",
   "metadata": {},
   "source": [
    "### 1.3. API 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a08ab5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ip]\n",
      "API_URI=http://api.aoikujira.com/ip/get.php\n",
      "REMOTE_ADDR=211.49.64.155\n",
      "REMOTE_HOST=211.49.64.155\n",
      "REMOTE_PORT=36814\n",
      "HTTP_HOST=api.aoikujira.com\n",
      "HTTP_USER_AGENT=Python-urllib/3.8\n",
      "HTTP_ACCEPT_LANGUAGE=\n",
      "HTTP_ACCEPT_CHARSET=\n",
      "SERVER_PORT=80\n",
      "FORMAT=ini\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 읽어들이기\n",
    "url=\"http://api.aoikujira.com/ip/ini\"\n",
    "res=request.urlopen(url)\n",
    "data=res.read()\n",
    "\n",
    "#바이너리를 문자열로 변환하기\n",
    "text=data.decode(\"utf-8\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338d83a",
   "metadata": {},
   "source": [
    "## 2. BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745ec865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86320120",
   "metadata": {},
   "source": [
    "### 2.1. 기본 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611b3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser') #HTML 분석하기\n",
    "\n",
    "#원하는 부분 추출하기\n",
    "h1 = soup.html.body.h1  #h1 태그를 접근하기 위해 html-body-h1 구조를 사용하여 soup.html.body.h1 이런식으로 이용\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling #p 태그는 두개가 있어 soup.html.body.p 한 후 next_sibling을 두번 이용하여 다음 p를 추출. 한번만 하면 그 다음 공백이 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87e90f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 스크레이핑이란?\n",
      "p  = 웹 페이지를 분석하는 것\n",
      "p  = 원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "#요소의 글자 출력하기\n",
    "\n",
    "print(f\"h1 = {h1.string}\")\n",
    "print(f\"p  = {p1.string}\")\n",
    "print(f\"p  = {p2.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58543e5",
   "metadata": {},
   "source": [
    "### 2.2 요소를 찾는 method <br>\n",
    "단일 element 추출 : find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ac7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feaf164",
   "metadata": {},
   "source": [
    "- 1) find() 메서드로 원하는 부분 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd0d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>스크레이핑이란?</h1>\n"
     ]
    }
   ],
   "source": [
    "#BeautifulSoup는 루트부터 하나하나 요소를 찾는 방법 말고도 find()라는 메소드를 제공\n",
    "title = soup.find(\"h1\") \n",
    "body  = soup.find(\"p\")\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312d37e",
   "metadata": {},
   "source": [
    "- 2) 텍스트 부분 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20b1a901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title = 스크레이핑이란?\n",
      "#body = 웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "print(f\"#title = {title.string}\" )\n",
    "print(f\"#body = {body.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fcc2a",
   "metadata": {},
   "source": [
    "복수 elements 추출: find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f878215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#여러개의 태그를 한번에 추출하고자 할때 사용함.\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def6e58",
   "metadata": {},
   "source": [
    "- 1) find_all() 메서드로 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5055022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://www.naver.com\">naver</a>, <a href=\"http://www.daum.net\">daum</a>] 2\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all(\"a\")\n",
    "print(links, len(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669cf84",
   "metadata": {},
   "source": [
    "- 2) 링크 목록 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922c2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "for a in links:\n",
    "    href = a.attrs['href'] # href의 속성에 있는 속성값을 추출\n",
    "    text = a.string \n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee2df7",
   "metadata": {},
   "source": [
    "## 3. Css Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9636ef",
   "metadata": {},
   "source": [
    "Css Selector란, 웹상의 요소에 css를 적용하기 위한 문법으로, 즉 요소를 선택하기 위한 패턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8eecd",
   "metadata": {},
   "source": [
    "- BeautifulSoup에서 Css Selector 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad73a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 \n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636690e5",
   "metadata": {},
   "source": [
    "필요한 부분을 CSS 쿼리로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba043710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 위키북스 도서\n",
      "li = 유니티 게임 이펙트 입문\n",
      "li = 스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "li = 모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "# 타이틀 부분 추출하기 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string #div id가 meigen인 곳에서 h1을 가져와라\n",
    "print(f\"h1 = {h1}\")\n",
    "\n",
    "# 목록 부분 추출하기 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\") #태그 안으로 점점 들어가는것! div태그/meigen/ui/items/li 가져와라\n",
    "for li in li_list:\n",
    "  print(f\"li = {li.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6104525",
   "metadata": {},
   "source": [
    "## 4. 활용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce121af",
   "metadata": {},
   "source": [
    "- URL을 이용하여 웹으로부터 html을 읽어들임 (urllib)\n",
    "- html 분석 및 원하는 데이터를 추출 (BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f16856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request, parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eeb38b",
   "metadata": {},
   "source": [
    "### 4.1. 네이버 금융 - 환율 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a0c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/krw = 1,178.00\n"
     ]
    }
   ],
   "source": [
    "#1) HTML 가져오기\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = request.urlopen(url)\n",
    "\n",
    "#2) HTML 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "#3) 원하는 데이터 추출하기\n",
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "    ##div태그 안 span.value값을 price라는 변수에 저장\n",
    "print(\"usd/krw =\", price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8aa9d",
   "metadata": {},
   "source": [
    "### 4.2 기상청 RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042ef70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=109\n",
      "서울,경기도 육상중기예보\n",
      "○ (강수) 29일(수)과 10월 6일(수)은 비가 내리겠습니다.<br />○ (기온) 이번 예보기간 아침최저기온은 12~19도로 어제(25일, 아침최저기온 15~20도)와 비슷하거나 조금 낮겠고, <br />          낮최고기온은 23~28도로 어제(25일, 낮최고기온 23~24도)보다 높겠습니다.<br />○ (해상) 서해중부해상의 물결은 1.0~2.0m로 일겠습니다.\n"
     ]
    }
   ],
   "source": [
    "#1) HTML 가져오기\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "\n",
    "#매개변수를 URL로 인코딩한다.\n",
    "values = {\n",
    "    'stnId':'109'\n",
    "}\n",
    "\n",
    "params=parse.urlencode(values)\n",
    "url += \"?\"+params # URL에 매개변수 추가\n",
    "print(\"url=\", url)\n",
    "\n",
    "res = request.urlopen(url)\n",
    "\n",
    "\n",
    "#2) HTML 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "#3) 원하는 데이터 추출하기\n",
    "header = soup.find(\"header\")\n",
    "\n",
    "title = header.find(\"title\").text\n",
    "wf = header.find(\"wf\").text\n",
    "\n",
    "print(title)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8b118",
   "metadata": {},
   "source": [
    "### 4.3. 윤동주 작가의 작품 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "253c4b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 하늘과 바람과 별과 시\n",
      "- 증보판\n",
      "- 서시\n",
      "- 자화상\n",
      "- 소년\n",
      "- 눈 오는 지도\n",
      "- 돌아와 보는 밤\n",
      "- 병원\n",
      "- 새로운 길\n",
      "- 간판 없는 거리\n",
      "- 태초의 아침\n",
      "- 또 태초의 아침\n",
      "- 새벽이 올 때까지\n",
      "- 무서운 시간\n",
      "- 십자가\n",
      "- 바람이 불어\n",
      "- 슬픈 족속\n",
      "- 눈감고 간다\n",
      "- 또 다른 고향\n",
      "- 길\n",
      "- 별 헤는 밤\n",
      "- 흰 그림자\n",
      "- 사랑스런 추억\n",
      "- 흐르는 거리\n",
      "- 쉽게 씌어진 시\n",
      "- 봄\n",
      "- 참회록\n",
      "- 간(肝)\n",
      "- 위로\n",
      "- 팔복\n",
      "- 못자는밤\n",
      "- 달같이\n",
      "- 고추밭\n",
      "- 아우의 인상화\n",
      "- 사랑의 전당\n",
      "- 이적\n",
      "- 비오는 밤\n",
      "- 산골물\n",
      "- 유언\n",
      "- 창\n",
      "- 바다\n",
      "- 비로봉\n",
      "- 산협의 오후\n",
      "- 명상\n",
      "- 소낙비\n",
      "- 한난계\n",
      "- 풍경\n",
      "- 달밤\n",
      "- 장\n",
      "- 밤\n",
      "- 황혼이 바다가 되어\n",
      "- 아침\n",
      "- 빨래\n",
      "- 꿈은 깨어지고\n",
      "- 산림\n",
      "- 이런날\n",
      "- 산상\n",
      "- 양지쪽\n",
      "- 닭\n",
      "- 가슴 1\n",
      "- 가슴 2\n",
      "- 비둘기\n",
      "- 황혼\n",
      "- 남쪽 하늘\n",
      "- 창공\n",
      "- 거리에서\n",
      "- 삶과 죽음\n",
      "- 초한대\n",
      "- 산울림\n",
      "- 해바라기 얼굴\n",
      "- 귀뚜라미와 나와\n",
      "- 애기의 새벽\n",
      "- 햇빛·바람\n",
      "- 반디불\n",
      "- 둘 다\n",
      "- 거짓부리\n",
      "- 눈\n",
      "- 참새\n",
      "- 버선본\n",
      "- 편지\n",
      "- 봄\n",
      "- 무얼 먹구 사나\n",
      "- 굴뚝\n",
      "- 햇비\n",
      "- 빗자루\n",
      "- 기왓장 내외\n",
      "- 오줌싸개 지도\n",
      "- 병아리\n",
      "- 조개껍질\n",
      "- 겨울\n",
      "- 트루게네프의 언덕\n",
      "- 달을 쏘다\n",
      "- 별똥 떨어진 데\n",
      "- 화원에 꽃이 핀다\n",
      "- 종시\n"
     ]
    }
   ],
   "source": [
    "# 뒤의 인코딩 부분은 \"저자:윤동주\"라는 의미입니다.\n",
    "# 따로 입력하지 말고 위키 문헌 홈페이지에 들어간 뒤에 주소를 복사해서 사용하세요.\n",
    "\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# #mw-content-text 바로 아래에 있는 \n",
    "# ul 태그 바로 아래에 있는\n",
    "# li 태그 아래에 있는\n",
    "# a 태그를 모두 선택합니다.\n",
    "a_list = soup.select(\"#mw-content-text   ul > li  a\")\n",
    "for a in a_list:\n",
    "    name = a.string\n",
    "    print(f\"- {name}\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d1de5",
   "metadata": {},
   "source": [
    "## 일반문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5ffa2",
   "metadata": {},
   "source": [
    "### 1. 네이버 뉴스 헤드라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58bb48de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        엔카, 보배드림, KB차차차, 케이카 '부당 환불제한' 조항 없어진다\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "관련기사 개수\n",
      "15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        中, 돌아온 멍완저우 ‘영웅대접’…대미외교 승리로 평가\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "관련기사 개수\n",
      "69\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        버스에 대변 누고 달아난 승객... 기사 \"급하면 세워드렸을 텐데\"\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "관련기사 개수\n",
      "15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        이재명 측 \"곽상도 아들 50억 원, 뇌물죄 수사해야\"\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "관련기사 개수\n",
      "82\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                        대학생단체 “노엘 불구속은 아빠 찬스”…장제원 “참담한 마음”\n",
      "                                    \n",
      "\n",
      "\n",
      "\n",
      "관련기사 개수\n",
      "51\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://news.naver.com/\"\n",
    "\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "selector = \"#today_main_news > div.hdline_news > ul\"\n",
    "for a in soup.select(selector):\n",
    "    title = a.text\n",
    "    print(title)\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1d2ef",
   "metadata": {},
   "source": [
    "### 2. 시민의 소리 게시판"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a029cf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['그늘막 텐트 문의', '감사 인사 드립니다.', '어린이대공원 매점 냉장고 점검 부탁드립니다.', '어린이를 위한 공원내 식당에 아기를 위한 시설 부족(아기의자가 왜 없죠?)', '강창수 해설사님 ', '동물해설사님 칭찬', '강창수 동물 해설사님', '놀이동산 푸드코트 김치가 중국산인 이유는?', '주슨트 설명 최고예요!!', '강창수 주슨트님 최고 !!'] ['https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210926000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210926000001&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210925000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210923000005&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210920000001&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210919000004&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210919000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210918000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210909000001&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=SuiBEfuiPxM3hHKusDNgq37Ia0evXTSfszh87koyKqz5JP3Tpre4muSrqmAQj1Tl.etisw1_servlet_user?qnaid=QNAS20210908000004&pgno=1']\n"
     ]
    }
   ],
   "source": [
    "url_head = \"https://www.sisul.or.kr\"\n",
    "\n",
    "url_board = url_head + \"/open_content/childrenpark/qna/qnaMsgList.do?pgno=1\"\n",
    "\n",
    "\n",
    "\n",
    "res = request.urlopen(url_board)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "titles = []\n",
    "links = []\n",
    "for a in soup.select(selector):\n",
    "    titles.append(a.text)\n",
    "    links.append(url_head + a.attrs[\"href\"])\n",
    "    \n",
    "print(titles, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e7363",
   "metadata": {},
   "source": [
    "### 추가내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bd043c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그늘막 텐트 문의</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>감사 인사 드립니다.</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>어린이대공원 매점 냉장고 점검 부탁드립니다.</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어린이를 위한 공원내 식당에 아기를 위한 시설 부족(아기의자가 왜 없죠?)</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>강창수 해설사님</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0                                  그늘막 텐트 문의   \n",
       "1                                감사 인사 드립니다.   \n",
       "2                   어린이대공원 매점 냉장고 점검 부탁드립니다.   \n",
       "3  어린이를 위한 공원내 식당에 아기를 위한 시설 부족(아기의자가 왜 없죠?)   \n",
       "4                                  강창수 해설사님    \n",
       "\n",
       "                                                link  \n",
       "0  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "1  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "2  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "3  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "4  https://www.sisul.or.kr/open_content/childrenp...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수집된 자료를 데이터프레임으로 만들어 csv로 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "board_df = pd.DataFrame({\"title\": titles, \"link\": links})\n",
    "board_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f177360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_df.to_csv(\"HW3_board.csv\", index=False) #데이터를 csv 파일로 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
